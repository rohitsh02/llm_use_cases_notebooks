{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ff9811-4c77-4231-8ac0-89154dfeeb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install --disable-pip-version-check \\\n",
    "    torch==1.13.1 \\\n",
    "    torchdata==0.5.1 \n",
    "\n",
    "%pip install \\\n",
    "    transformers==4.27.2 \\\n",
    "    datasets==2.11.0 \\\n",
    "    evaluate==0.4.0 \\\n",
    "    rouge_score==0.1.2 \\\n",
    "    loralib==0.1.1 \\\n",
    "    peft==0.3.0 \\\n",
    "    safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3d2883-aefe-4c30-93f4-0ea582a94c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n",
    "import torch\n",
    "import time\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279c707f-64a0-440c-afdb-03588c2ec78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
    "\n",
    "dataset = load_dataset(huggingface_dataset_name)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bf9e18-f316-46c3-8c69-cf55843b02e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='google/flan-t5-base'\n",
    "\n",
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c642a779-576e-49ac-8b8d-4788ab0f7b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d84234d-8373-4615-8db9-8153d1a54ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    start_prompt = 'Summarize the following conversation.\\n\\n'\n",
    "    end_prompt = '\\n\\nSummary: '\n",
    "    prompt = [start_prompt + dialogue + end_prompt for dialogue in example[\"dialogue\"]]\n",
    "    example['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    example['labels'] = tokenizer(example[\"summary\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    return example\n",
    "\n",
    "# The dataset actually contains 3 diff splits: train, validation, test.\n",
    "# The tokenize_function code is handling all data across all splits in batches.\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['id', 'topic', 'dialogue', 'summary',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a759a44-8024-4d46-b94f-c6d4a1315e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32, # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf24bcc-a3e6-498e-a9f2-25d08c427dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model = get_peft_model(original_model, \n",
    "                            lora_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e931b7-74dd-4333-8fc9-7ae1ffbe4741",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f'./peft-dialogue-summary-training-{str(int(time.time()))}'\n",
    "\n",
    "peft_training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    auto_find_batch_size=True,\n",
    "    learning_rate=1e-3, # Higher learning rate than full fine-tuning.\n",
    "    num_train_epochs=10,\n",
    "    logging_steps=2,\n",
    "    max_steps=20    \n",
    ")\n",
    "    \n",
    "peft_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=peft_training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e94e0ab-fa34-483d-9f53-d26671880494",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_trainer.train()\n",
    "\n",
    "peft_model_path=\"./peft-dialogue-summary-checkpoint-local-lora-model\"\n",
    "\n",
    "#peft_trainer.model.save_pretrained(peft_model_path)\n",
    "#tokenizer.save_pretrained(peft_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7769ce-3614-4999-b3b6-08ca68224b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_trainer.model.save_pretrained(peft_model_path) #\n",
    "tokenizer.save_pretrained(peft_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9136fad3-9403-4ef1-b8e8-54fb2b8b0e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_save_path = \"peft_merged_flan-model\"\n",
    "merged_model = peft_model.merge_and_unload()\n",
    "merged_model.save_pretrained(merge_save_path,safe_serialization=False)\n",
    "tokenizer.save_pretrained(merge_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75258e65-0a79-4548-b618-0d305e112ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r fine-tuned-flan5.zip ./merge_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b32eebb-2041-422b-bf5e-7851cd31dd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -m cp -r ./fine-tuned-flan5.zip gs://my_gcs_bucket/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caadb009-0876-4351-9d27-ba4d6c067ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l merged_model"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-gpu.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-gpu:m111"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
